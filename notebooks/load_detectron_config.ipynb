{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/workspace/my_proposal\")\n",
    "from detectron2.config import CfgNode, get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from scripts.open_vocab_seg.segmentor import Segmentor\n",
    "from scripts.datasets.dataset_mapper import MaskFormerSemanticDatasetMapper\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cfg = get_cfg()\n",
    "base_cfg.MODEL.DINO = CfgNode()\n",
    "base_cfg.MODEL.DINO.SIZE = \"small\"\n",
    "# cfg.merge_from_other_cfg(\"../configs/seg.yaml\")\n",
    "# print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ade20k_sem_seg_val',)\n"
     ]
    }
   ],
   "source": [
    "cfg = CfgNode(CfgNode.load_yaml_with_base(\"../configs/seg.yaml\"))\n",
    "cfg.MODEL.DEVICE=\"cpu\"\n",
    "cfg.DATASETS.TRAIN=(\"ade20k_sem_seg_val\",)\n",
    "cfg.freeze()\n",
    "print(cfg.DATASETS.TRAIN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_lr_scheduler(cls, cfg, optimizer):\n",
    "        return \"Test\"\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return \"Test\"\n",
    "        # return super().build_train_loader(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = MaskFormerSemanticDatasetMapper(cfg, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspace/my_proposal/notebooks/load_detectron_config.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f616666656374696f6e6174655f77696c736f6e227d/workspace/my_proposal/notebooks/load_detectron_config.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m test_dict \u001b[39m=\u001b[39m{\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f616666656374696f6e6174655f77696c736f6e227d/workspace/my_proposal/notebooks/load_detectron_config.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfile_name\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39m/workspace/data/ADE20K_2021_17_01/images_detectron2/validation/ADE_val_00000001.jpg\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f616666656374696f6e6174655f77696c736f6e227d/workspace/my_proposal/notebooks/load_detectron_config.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msem_seg_file_name\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39m/workspace/data/ADE20K_2021_17_01/annotations_detectron2/validation/ADE_val_00000001.tif\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f616666656374696f6e6174655f77696c736f6e227d/workspace/my_proposal/notebooks/load_detectron_config.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m }\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f616666656374696f6e6174655f77696c736f6e227d/workspace/my_proposal/notebooks/load_detectron_config.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m mapper(test_dict)\n",
      "File \u001b[0;32m/workspace/my_proposal/scripts/datasets/dataset_mapper.py:104\u001b[0m, in \u001b[0;36mMaskFormerSemanticDatasetMapper.__call__\u001b[0;34m(self, dataset_dict)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     98\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot find \u001b[39m\u001b[39m'\u001b[39m\u001b[39msem_seg_file_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m for semantic segmentation dataset \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     99\u001b[0m             dataset_dict[\u001b[39m\"\u001b[39m\u001b[39mfile_name\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    100\u001b[0m         )\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    103\u001b[0m aug_input \u001b[39m=\u001b[39m T\u001b[39m.\u001b[39mAugInput(image, sem_seg\u001b[39m=\u001b[39msem_seg_gt)\n\u001b[0;32m--> 104\u001b[0m aug_input, transforms \u001b[39m=\u001b[39m T\u001b[39m.\u001b[39;49mapply_transform_gens(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtfm_gens,aug_input)\n\u001b[1;32m    105\u001b[0m image \u001b[39m=\u001b[39m aug_input\u001b[39m.\u001b[39mimage\n\u001b[1;32m    106\u001b[0m sem_seg_gt \u001b[39m=\u001b[39m aug_input\u001b[39m.\u001b[39msem_seg\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/detectron2/data/transforms/augmentation.py:363\u001b[0m, in \u001b[0;36mapply_augmentations\u001b[0;34m(augmentations, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    362\u001b[0m     image_only \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m tfms \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39;49mapply_augmentations(augmentations)\n\u001b[1;32m    364\u001b[0m \u001b[39mreturn\u001b[39;00m inputs\u001b[39m.\u001b[39mimage \u001b[39mif\u001b[39;00m image_only \u001b[39melse\u001b[39;00m inputs, tfms\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/detectron2/data/transforms/augmentation.py:350\u001b[0m, in \u001b[0;36mAugInput.apply_augmentations\u001b[0;34m(self, augmentations)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_augmentations\u001b[39m(\n\u001b[1;32m    345\u001b[0m     \u001b[39mself\u001b[39m, augmentations: List[Union[Augmentation, Transform]]\n\u001b[1;32m    346\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m TransformList:\n\u001b[1;32m    347\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[39m    Equivalent of ``AugmentationList(augmentations)(self)``\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m     \u001b[39mreturn\u001b[39;00m AugmentationList(augmentations)(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/detectron2/data/transforms/augmentation.py:267\u001b[0m, in \u001b[0;36mAugmentationList.__call__\u001b[0;34m(self, aug_input)\u001b[0m\n\u001b[1;32m    265\u001b[0m tfms \u001b[39m=\u001b[39m []\n\u001b[1;32m    266\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugs:\n\u001b[0;32m--> 267\u001b[0m     tfm \u001b[39m=\u001b[39m x(aug_input)\n\u001b[1;32m    268\u001b[0m     tfms\u001b[39m.\u001b[39mappend(tfm)\n\u001b[1;32m    269\u001b[0m \u001b[39mreturn\u001b[39;00m TransformList(tfms)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/detectron2/data/transforms/augmentation.py:168\u001b[0m, in \u001b[0;36mAugmentation.__call__\u001b[0;34m(self, aug_input)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[39mAugment the given `aug_input` **in-place**, and return the transform that's used.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39m    Transform: the transform that is applied on the input.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m args \u001b[39m=\u001b[39m _get_aug_input_args(\u001b[39mself\u001b[39m, aug_input)\n\u001b[0;32m--> 168\u001b[0m tfm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_transform(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    169\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tfm, (Transform, TransformList)), (\n\u001b[1;32m    170\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m.get_transform must return an instance of Transform! \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(tfm)\u001b[39m}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    173\u001b[0m aug_input\u001b[39m.\u001b[39mtransform(tfm)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/detectron2/data/transforms/augmentation_impl.py:464\u001b[0m, in \u001b[0;36mRandomCrop_CategoryAreaConstraint.get_transform\u001b[0;34m(self, image, sem_seg)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_transform\u001b[39m(\u001b[39mself\u001b[39m, image, sem_seg):\n\u001b[1;32m    463\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msingle_category_max_area \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[0;32m--> 464\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcrop_aug\u001b[39m.\u001b[39;49mget_transform(image)\n\u001b[1;32m    465\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m         h, w \u001b[39m=\u001b[39m sem_seg\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/detectron2/data/transforms/augmentation_impl.py:402\u001b[0m, in \u001b[0;36mRandomCrop.get_transform\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_transform\u001b[39m(\u001b[39mself\u001b[39m, image):\n\u001b[1;32m    401\u001b[0m     h, w \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mshape[:\u001b[39m2\u001b[39m]\n\u001b[0;32m--> 402\u001b[0m     croph, cropw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_crop_size((h, w))\n\u001b[1;32m    403\u001b[0m     \u001b[39massert\u001b[39;00m h \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m croph \u001b[39mand\u001b[39;00m w \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m cropw, \u001b[39m\"\u001b[39m\u001b[39mShape computation in \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m has bugs.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m)\n\u001b[1;32m    404\u001b[0m     h0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(h \u001b[39m-\u001b[39m croph \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/detectron2/data/transforms/augmentation_impl.py:425\u001b[0m, in \u001b[0;36mRandomCrop.get_crop_size\u001b[0;34m(self, image_size)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mint\u001b[39m(h \u001b[39m*\u001b[39m ch \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m), \u001b[39mint\u001b[39m(w \u001b[39m*\u001b[39m cw \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m)\n\u001b[1;32m    424\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrop_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabsolute\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 425\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mmin\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcrop_size[\u001b[39m0\u001b[39;49m], h), \u001b[39mmin\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrop_size[\u001b[39m1\u001b[39m], w))\n\u001b[1;32m    426\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrop_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabsolute_range\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    427\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrop_size[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrop_size[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "test_dict ={\n",
    "    \"file_name\":\"/workspace/data/ADE20K_2021_17_01/images_detectron2/validation/ADE_val_00000001.jpg\",\n",
    "    \"sem_seg_file_name\":\"/workspace/data/ADE20K_2021_17_01/annotations_detectron2/validation/ADE_val_00000001.tif\"\n",
    "}\n",
    "mapper(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/09 14:59:22 d2.engine.defaults]: \u001b[0mModel:\n",
      "Segmentor(\n",
      "  (backbone): DinoVisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))\n",
      "      (norm): Identity()\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x NestedTensorBlock(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): MemEffAttention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "    (head): Identity()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
